{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ine-divider](https://user-images.githubusercontent.com/7065401/92672068-398e8080-f2ee-11ea-82d6-ad53f7feb5c0.png)\n",
    "<hr>\n",
    "\n",
    "### MySQL and MariaDB for Python Developers\n",
    "# Working with the Python DBA and MySQL\n",
    "\n",
    "In this project, you will practice using Python's DB-API to access MySQL (or MariaDB).\n",
    "\n",
    "You will need access to a MySQL installation where you have superuser permissions. If you do not have such access elsewhere, installing to your personal workstation is a good idea.  Alternately, you might wish to use a Docker container for a self-contained installation.  See `https://hub.docker.com/_/mysql` for details on that option.  \n",
    "\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/92672455-187a5f80-f2ef-11ea-890c-40be9474f7b7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "**Move data into MySQL**\n",
    "\n",
    "In this respository, there is an SQLite database called `Airline-Tweets.sqlite`.  The lesson briefly mentioned `sqlite3` as a module in the standard library that will interact with single-file relational databases.  In particular, `sqlite3`, like `mysql.connector` generally follows the DB-API.  Although more specifics of the MySQL data definition language (DDL) are discussed in a later lesson, we assume you have a basic familiarity with the the SQL `CREATE TABLE` command for this purpose.\n",
    "\n",
    "The scenario posed in this problem is that you have some data in a different database (SQLite), and you wish to transfer all contents to MySQL.  Moreover, you wish to do this *entirely* within Python and using the DB-API.  You will need to determine the structure and data types of the SQLite data, create an appropriate MySQL table, and transfer all rows into MySQL.  This particular SQLite data file contains only one table, named `Tweets` (about customer ratings of airlines).\n",
    "\n",
    "To get a partial view of the kind of data we are transferring, this is a query performed within the `sqlite` command shell, which is generally similar to the `mysql` command shell that is discussed in later lessons.  However, you should perform all your work in Python for this project (the example does **not** list all the columns).\n",
    "\n",
    "```\n",
    "$ sqlite Airline-Tweets.sqlite\n",
    "SQLite version 3.33.0 2020-08-14 13:23:32\n",
    "Enter \".help\" for usage hints.\n",
    "sqlite> SELECT tweet_id, airline, airline_sentiment, tweet_created FROM Tweets LIMIT 5;\n",
    "tweet_id            airline    airline_sentiment  tweet_created\n",
    "------------------  ---------  -----------------  -------------------------\n",
    "567588278875213824  Delta      neutral            2015-02-16 23:36:05 -0800\n",
    "567590027375702016  Delta      negative           2015-02-16 23:43:02 -0800\n",
    "567591480085463040  United     negative           2015-02-16 23:48:48 -0800\n",
    "567592368451248130  United     negative           2015-02-16 23:52:20 -0800\n",
    "567594449874587648  Southwest  negative           2015-02-17 00:00:36 -0800\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import sqlite3\n",
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**\n",
    "\n",
    "Unfortunately, the `cursor.description` in `sqlite3` isn't as informative as one might like.  For guidance, you can look at this:\n",
    "\n",
    "```\n",
    "sqlite> pragma table_info('Tweets');\n",
    "cid  name                          type     notnull  dflt_value  pk\n",
    "---  ----------------------------  -------  -------  ----------  --\n",
    "0    tweet_id                      INTEGER  0                    1\n",
    "1    airline_sentiment             TEXT     0                    0\n",
    "2    airline_sentiment_confidence  NUMERIC  0                    0\n",
    "3    negativereason                TEXT     0                    0\n",
    "4    negativereason_confidence     NUMERIC  0                    0\n",
    "5    airline                       TEXT     0                    0\n",
    "6    airline_sentiment_gold        TEXT     0                    0\n",
    "7    name                          TEXT     0                    0\n",
    "8    negativereason_gold           TEXT     0                    0\n",
    "9    retweet_count                 INTEGER  0                    0\n",
    "10   text                          TEXT     0                    0\n",
    "11   tweet_coord                   TEXT     0                    0\n",
    "12   tweet_created                 TEXT     0                    0\n",
    "13   tweet_location                TEXT     0                    0\n",
    "14   user_timezone                 TEXT     0                    0\n",
    "```\n",
    "\n",
    "It is wise also to examine some sample rows to decide the best MySQL data types.  SQLite is more generic than MySQL about data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A possible solution**\n",
    "\n",
    "You will need to make some decisions about data types and other details. These are plausible answers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, pwd, db = 'ine_student', 'ine-password', 'ine'\n",
    "host, port = 'localhost', '3306'\n",
    "con_dest = mysql.connector.connect(database=db, host=host, user=user, password=pwd, port=port)\n",
    "cur_dest = con_dest.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create MySQL table\n",
    "sql_create_tweets = '''\n",
    "CREATE TABLE IF NOT EXISTS Tweets (\n",
    "    tweet_id DECIMAL(18) PRIMARY KEY,\n",
    "    airline_sentiment TEXT,\n",
    "    airline_sentiment_confidence REAL,\n",
    "    negativereason TEXT,\n",
    "    negativereason_confidence REAL,\n",
    "    airline TEXT,\n",
    "    airline_sentiment_gold TEXT,\n",
    "    name TEXT,\n",
    "    negativereason_gold TEXT,\n",
    "    retweet_count INT,\n",
    "    text TEXT,\n",
    "    tweet_coord TEXT,\n",
    "    tweet_created TIMESTAMP,\n",
    "    tweet_location TEXT,\n",
    "    user_timezone TEXT\n",
    "    );\n",
    "'''\n",
    "cur_dest.execute(\"DROP TABLE IF EXISTS Tweets;\")\n",
    "cur_dest.execute(sql_create_tweets)\n",
    "con_dest.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7efce41e1030>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_src = sqlite3.connect('Airline-Tweets.sqlite') \n",
    "cur_src = con_src.cursor()\n",
    "cur_src.execute(\"SELECT * FROM Tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious approach will fail because some numeric values are missing, but SQLite gives you an empty string rather than `None`.  We can fix that in Python.  We also have a problem with timestamp.  MySQL needs it without the offset, but we should set that offset manually first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset indicated in SQLite\n",
    "cur_dest.execute(\"SET time_zone = '-08:00';\")\n",
    "\n",
    "sql_insert = \"\"\"\n",
    "INSERT INTO Tweets \n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "for src_row in cur_src:\n",
    "    row = [data or None for data in src_row]\n",
    "    timestamp = row[12][:19]  # Omit offset portion\n",
    "    row[12] = timestamp\n",
    "    row = tuple(row)\n",
    "    cur_dest.execute(sql_insert, row)\n",
    "    \n",
    "con_dest.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airline': 'Delta',\n",
      " 'airline_sentiment': 'neutral',\n",
      " 'airline_sentiment_confidence': 1.0,\n",
      " 'airline_sentiment_gold': None,\n",
      " 'name': 'JetBlueNews',\n",
      " 'negativereason': None,\n",
      " 'negativereason_confidence': None,\n",
      " 'negativereason_gold': None,\n",
      " 'retweet_count': None,\n",
      " 'text': \"@JetBlue's new CEO seeks the right balance to please passengers and \"\n",
      "         'Wall ... - Greenfield Daily Reporter http://t.co/LM3opxkxch',\n",
      " 'tweet_coord': None,\n",
      " 'tweet_created': datetime.datetime(2015, 2, 16, 23, 36, 5),\n",
      " 'tweet_id': Decimal('567588278875213824'),\n",
      " 'tweet_location': 'USA',\n",
      " 'user_timezone': 'Sydney'}\n",
      "{'airline': 'Delta',\n",
      " 'airline_sentiment': 'negative',\n",
      " 'airline_sentiment_confidence': 1.0,\n",
      " 'airline_sentiment_gold': None,\n",
      " 'name': 'nesi_1992',\n",
      " 'negativereason': \"Can't Tell\",\n",
      " 'negativereason_confidence': 0.6503,\n",
      " 'negativereason_gold': None,\n",
      " 'retweet_count': None,\n",
      " 'text': '@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ #nothappy',\n",
      " 'tweet_coord': None,\n",
      " 'tweet_created': datetime.datetime(2015, 2, 16, 23, 43, 2),\n",
      " 'tweet_id': Decimal('567590027375702016'),\n",
      " 'tweet_location': 'undecided',\n",
      " 'user_timezone': 'Pacific Time (US & Canada)'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "cur_dest.execute(\"SELECT * FROM Tweets LIMIT 2;\")\n",
    "cols = [c[0] for c in cur_dest.description]\n",
    "for row in cur_dest:\n",
    "    pprint(dict(zip(cols, row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/92672455-187a5f80-f2ef-11ea-890c-40be9474f7b7.png)\n",
    "\n",
    "## Part 2\n",
    "\n",
    "**Skipping problem data when loading**\n",
    "\n",
    "For this task, we will largely repeat the steps fo the first task.  However, you probably encountered certain problems with the data transfer that you had to manually remediate using Python code.  Rather than \"fix up\" the data in Python, for this version you should simply transfer the unproblematic data, but create another table called `data_issues` where you store the unique `tweet_id` of the problem row, and the error message that occurred.\n",
    "\n",
    "In your solution, **some** data will transfer without remediation, and other data will be marked for later processing in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import sqlite3\n",
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A possible solution**\n",
    "\n",
    "We assume for this solution that the target table `Tweets` is created with the same definition as in the prior part. This is a situationâ€”when we wait for exception from MySQLâ€”where a connection pool can help us greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_create_issues = \"\"\"\n",
    "CREATE TABLE data_issues (\n",
    "    tweet_id DECIMAL(18) PRIMARY KEY, \n",
    "    message TEXT\n",
    "    );\n",
    "\"\"\"\n",
    "# Clear out old content of dest\n",
    "cur_dest.execute('DROP TABLE IF EXISTS data_issues;')\n",
    "cur_dest.execute(sql_create_issues)\n",
    "cur_dest.execute('DROP TABLE IF EXISTS Tweets')\n",
    "cur_dest.execute(sql_create_tweets)\n",
    "con_dest.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "from queue import Queue\n",
    "qsize = 20\n",
    "pool = Queue(maxsize=qsize)  \n",
    "for _ in range(qsize):\n",
    "    conn = mysql.connector.connect(\n",
    "                database=db, host=host, user=user, password=pwd, port=port)\n",
    "    pool.put(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, the timestamp format we simply have to fix, \n",
    "# the NULL issue we can separate out\n",
    "\n",
    "def add_row(pool, row):\n",
    "    conn = pool.get()\n",
    "    cursor = conn.cursor()    \n",
    "    try:\n",
    "        row = list(row)\n",
    "        row[12] = row[12][:19]  # Omit offset portion\n",
    "        cursor.execute(sql_insert, tuple(row))\n",
    "    except Exception as err:\n",
    "        conn.rollback()\n",
    "        cursor.execute(\"INSERT INTO data_issues VALUES (%s, %s);\",\n",
    "                       (row[0], str(err)))\n",
    "    finally:\n",
    "        conn.commit()\n",
    "        pool.put(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.89 s, sys: 4.63 s, total: 14.5 s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cur_src.execute(\"SELECT * FROM Tweets\")\n",
    "\n",
    "for row in cur_src:\n",
    "    t = Thread(target=add_row, args=(pool, row))\n",
    "    t.start()\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10416,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dest.execute('SELECT count(*) FROM Tweets;')\n",
    "cur_dest.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Decimal('567588278875213824'),\n",
       "  \"1265 (01000): Data truncated for column 'negativereason_confidence' at row 1\"),\n",
       " (Decimal('567634106058821632'),\n",
       "  \"1265 (01000): Data truncated for column 'negativereason_confidence' at row 1\"),\n",
       " (Decimal('567643252753694721'),\n",
       "  \"1265 (01000): Data truncated for column 'negativereason_confidence' at row 1\"),\n",
       " (Decimal('567655489119326209'),\n",
       "  \"1265 (01000): Data truncated for column 'negativereason_confidence' at row 1\"),\n",
       " (Decimal('567667301067915264'),\n",
       "  \"1265 (01000): Data truncated for column 'negativereason_confidence' at row 1\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dest.execute(\"SELECT * FROM data_issues LIMIT 5;\")\n",
    "cur_dest.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dest.execute(\"SELECT count(*) FROM data_issues;\")\n",
    "cur_dest.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/92672455-187a5f80-f2ef-11ea-890c-40be9474f7b7.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
